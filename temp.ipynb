{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3dcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0305cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# Input\n",
    "x = torch.tensor([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc81597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: {7.0}\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "y_pred = w * x + b\n",
    "print(\"y_pred:\", {y_pred.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649525e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: {9.0}\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "loss = (y_pred - y_true) ** 2\n",
    "print(\"Loss:\", {loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625f0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant backward: w.grad = None\n"
     ]
    }
   ],
   "source": [
    "print(\"Avant backward: w.grad =\", w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4119fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ff1c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après backward: w.grad = tensor([-18.])\n",
      "Apres backward: b.grad = tensor([-6.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Après backward: w.grad =\", w.grad)\n",
    "print(\"Apres backward: b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62da28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with torch.no_grad(): # Désactiver le tracking des gradients pour l'update w = w + alpha * w\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd547104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau poids : w = tensor([2.1800], requires_grad=True) b = tensor([1.0600], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveau poids : w =\", w, \"b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7cd113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après zero_(): w.grad = tensor([0.]) b.grad = tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Réinitialiser les gradients\n",
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(\"Après zero_(): w.grad =\", w.grad, \"b.grad =\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efea9980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids : Parameter containing:\n",
      "tensor([[-0.5861]], requires_grad=True)\n",
      "Biais : Parameter containing:\n",
      "tensor([-0.7771], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "perceptron = nn.Linear(1, 1)\n",
    "\n",
    "# Voir les poids initiaux\n",
    "print(\"Poids :\", perceptron.weight)\n",
    "print(\"Biais :\", perceptron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2015071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([3.])\n",
      "tensor([-2.5355], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "x = torch.tensor([3.0]) # Shape (batch_size, features)\n",
    "print(f\"input : {x}\")\n",
    "y_pred = perceptron(x)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc0fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "y_true = torch.tensor([10.0])\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dd9f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(157.1384, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cdd0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b96c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient de poids : tensor([[-75.2129]])\n",
      "Gradient de biais : tensor([-25.0710])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient de poids : {perceptron.weight.grad}\")\n",
    "print(f\"Gradient de biais : {perceptron.bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9de3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(perceptron.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1030f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90abcca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau poids : Parameter containing:\n",
      "tensor([[0.1660]], requires_grad=True)\n",
      "Nouveau biais : Parameter containing:\n",
      "tensor([-0.5264], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Nouveau poids :\", perceptron.weight)\n",
    "print(\"Nouveau biais :\", perceptron.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1c707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87daca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids après zero_grad : None\n",
      "Biais après zero_grad : None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Poids après zero_grad : {perceptron.weight.grad}\")\n",
    "print(f\"Biais après zero_grad : {perceptron.bias.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf98ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79448116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d73c7957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eae47c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0])\n",
    "y = torch.tensor([5.0])\n",
    "y_pred = model(x)\n",
    "loss = nn.MSELoss()(y_pred, y)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d17a0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02461311",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7553f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "315d9f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(training_data.classes)\n",
    "print(training_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad10a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bc78dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "491a756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f262e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0437,  0.0336, -0.0661, -0.0318, -0.0630,  0.0679, -0.0512, -0.0527,\n",
       "          0.1039, -0.1335]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e065d4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1058, 0.1047, 0.0948, 0.0981, 0.0951, 0.1084, 0.0962, 0.0961, 0.1123,\n",
       "         0.0886]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cf926d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred_probab.argmax(dim=1)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf529cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7dd7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch_value in enumerate(dataloader):\n",
    "        X, y = batch_value\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b5c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d269dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\Documents\\IIM\\DEEP_LEARNING\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.257722  [   64/60000]\n",
      "loss: 0.317461  [ 6464/60000]\n",
      "loss: 0.289523  [12864/60000]\n",
      "loss: 0.095424  [19264/60000]\n",
      "loss: 0.110563  [25664/60000]\n",
      "loss: 0.138368  [32064/60000]\n",
      "loss: 0.066612  [38464/60000]\n",
      "loss: 0.087207  [44864/60000]\n",
      "loss: 0.166682  [51264/60000]\n",
      "loss: 0.089349  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.102443 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.040872  [   64/60000]\n",
      "loss: 0.054087  [ 6464/60000]\n",
      "loss: 0.030931  [12864/60000]\n",
      "loss: 0.076550  [19264/60000]\n",
      "loss: 0.044052  [25664/60000]\n",
      "loss: 0.020273  [32064/60000]\n",
      "loss: 0.019043  [38464/60000]\n",
      "loss: 0.078896  [44864/60000]\n",
      "loss: 0.081676  [51264/60000]\n",
      "loss: 0.018332  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.078491 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.012038  [   64/60000]\n",
      "loss: 0.083925  [ 6464/60000]\n",
      "loss: 0.016305  [12864/60000]\n",
      "loss: 0.027948  [19264/60000]\n",
      "loss: 0.037500  [25664/60000]\n",
      "loss: 0.023734  [32064/60000]\n",
      "loss: 0.190250  [38464/60000]\n",
      "loss: 0.019253  [44864/60000]\n",
      "loss: 0.175268  [51264/60000]\n",
      "loss: 0.013438  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.069386 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.021785  [   64/60000]\n",
      "loss: 0.103788  [ 6464/60000]\n",
      "loss: 0.023353  [12864/60000]\n",
      "loss: 0.019844  [19264/60000]\n",
      "loss: 0.011442  [25664/60000]\n",
      "loss: 0.123930  [32064/60000]\n",
      "loss: 0.003793  [38464/60000]\n",
      "loss: 0.015272  [44864/60000]\n",
      "loss: 0.017351  [51264/60000]\n",
      "loss: 0.133802  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.073293 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.085217  [   64/60000]\n",
      "loss: 0.011314  [ 6464/60000]\n",
      "loss: 0.063049  [12864/60000]\n",
      "loss: 0.016347  [19264/60000]\n",
      "loss: 0.017850  [25664/60000]\n",
      "loss: 0.002151  [32064/60000]\n",
      "loss: 0.100985  [38464/60000]\n",
      "loss: 0.046263  [44864/60000]\n",
      "loss: 0.015928  [51264/60000]\n",
      "loss: 0.067714  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.075396 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.004356  [   64/60000]\n",
      "loss: 0.004451  [ 6464/60000]\n",
      "loss: 0.014030  [12864/60000]\n",
      "loss: 0.021310  [19264/60000]\n",
      "loss: 0.071178  [25664/60000]\n",
      "loss: 0.014314  [32064/60000]\n",
      "loss: 0.041329  [38464/60000]\n",
      "loss: 0.002563  [44864/60000]\n",
      "loss: 0.018788  [51264/60000]\n",
      "loss: 0.005337  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.077539 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.009262  [   64/60000]\n",
      "loss: 0.004062  [ 6464/60000]\n",
      "loss: 0.001341  [12864/60000]\n",
      "loss: 0.010806  [19264/60000]\n",
      "loss: 0.001711  [25664/60000]\n",
      "loss: 0.041043  [32064/60000]\n",
      "loss: 0.003584  [38464/60000]\n",
      "loss: 0.003468  [44864/60000]\n",
      "loss: 0.066148  [51264/60000]\n",
      "loss: 0.004673  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.066391 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.001716  [   64/60000]\n",
      "loss: 0.000892  [ 6464/60000]\n",
      "loss: 0.010801  [12864/60000]\n",
      "loss: 0.001539  [19264/60000]\n",
      "loss: 0.004304  [25664/60000]\n",
      "loss: 0.018885  [32064/60000]\n",
      "loss: 0.002051  [38464/60000]\n",
      "loss: 0.001808  [44864/60000]\n",
      "loss: 0.015168  [51264/60000]\n",
      "loss: 0.045164  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.068731 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.005332  [   64/60000]\n",
      "loss: 0.002344  [ 6464/60000]\n",
      "loss: 0.000566  [12864/60000]\n",
      "loss: 0.000919  [19264/60000]\n",
      "loss: 0.030027  [25664/60000]\n",
      "loss: 0.001435  [32064/60000]\n",
      "loss: 0.001467  [38464/60000]\n",
      "loss: 0.000590  [44864/60000]\n",
      "loss: 0.005102  [51264/60000]\n",
      "loss: 0.015064  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.078405 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.009837  [   64/60000]\n",
      "loss: 0.000283  [ 6464/60000]\n",
      "loss: 0.001273  [12864/60000]\n",
      "loss: 0.000361  [19264/60000]\n",
      "loss: 0.000592  [25664/60000]\n",
      "loss: 0.000967  [32064/60000]\n",
      "loss: 0.001633  [38464/60000]\n",
      "loss: 0.093403  [44864/60000]\n",
      "loss: 0.063332  [51264/60000]\n",
      "loss: 0.001030  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.081734 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     test(test_dataloader, model, loss_fn)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      2\u001b[39m size = \u001b[38;5;28mlen\u001b[39m(dataloader.dataset)\n\u001b[32m      3\u001b[39m model.train()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_value\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thoma\\Documents\\IIM\\DEEP_LEARNING\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thoma\\Documents\\IIM\\DEEP_LEARNING\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thoma\\Documents\\IIM\\DEEP_LEARNING\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1441\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thoma\\Documents\\IIM\\DEEP_LEARNING\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1263\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1264\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1278\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1279\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1280\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:256\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:329\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    327\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:878\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    875\u001b[39m                 ready_objects.add(o)\n\u001b[32m    876\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    880\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\connection.py:810\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m    808\u001b[39m ready = []\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m     res = _winapi.WaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m    812\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(training_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d891bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `NeuralNetwork([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `NeuralNetwork([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    }
   ],
   "source": [
    "example_inputs = (torch.randn(1, 1, 28, 28),)\n",
    "model.to('cpu')\n",
    "onnx_program = torch.onnx.export(model, example_inputs, dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2efb6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fdcc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 0.0, 'max': 1.0, 'mean': 0.14806422591209412, 'zeros': 596, 'nonzeros': 188, 'first_row': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'last_row': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect pixel values sent to the model (black vs white)\n",
    "try:\n",
    "    sample_img, _ = training_data[5]\n",
    "except NameError:\n",
    "    from torchvision import datasets, transforms\n",
    "    sample_img, _ = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())[0]\n",
    "\n",
    "img = sample_img.squeeze()  # (28, 28)\n",
    "flat = img.flatten()\n",
    "min_val = flat.min().item()\n",
    "max_val = flat.max().item()\n",
    "mean_val = flat.mean().item()\n",
    "zeros = (flat == 0).sum().item()\n",
    "nonzeros = flat.numel() - zeros\n",
    "first_row = img[0].tolist()\n",
    "last_row = img[-1].tolist()\n",
    "\n",
    "print({\n",
    "    'min': min_val,\n",
    "    'max': max_val,\n",
    "    'mean': mean_val,\n",
    "    'zeros': zeros,\n",
    "    'nonzeros': nonzeros,\n",
    "    'first_row': first_row,\n",
    "    'last_row': last_row,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
